â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HYBRID TRENDING SYSTEM                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚   Database    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤  Cache Layer   â”‚              â”‚
â”‚  â”‚   (Persistent)â”‚         â”‚  (In-Memory)   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚          â–²                         â–²                         â”‚
â”‚          â”‚                         â”‚                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚         Orchestrator Engine              â”‚              â”‚
â”‚  â”‚   (Decides what/when to update)          â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚          â”‚                         â”‚                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  On-Chain      â”‚       â”‚  Social Media  â”‚              â”‚
â”‚  â”‚  Aggregator    â”‚       â”‚  Aggregator    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **ğŸ”„ Three-Phase Strategy**

### **Phase 1: Initial Bootstrap (Run Once at Startup)**
### **Phase 2: Continuous On-Chain Monitoring (Every 1-5 minutes)**
### **Phase 3: Smart Social Updates (Every 5-15 minutes, selective)**

---

## **Phase 1: Initial Bootstrap** ğŸš€

**Goal**: Create initial trending list using ONLY on-chain data

### **Step 1.1: Collect Token Universe**
```
Input: List of ALL tokens you want to track (e.g., 1000 tokens)

For each token:
  â””â”€â”€ Fetch historical transactions (via your indexer)
  â””â”€â”€ Fetch current market data (DexScreener API)
  â””â”€â”€ Store in database
```

### **Step 1.2: Batch On-Chain Analysis**
```
For each token (parallel processing in batches of 50):
  â”œâ”€â”€ Run OnChainAggregator.analyzeOnChain()
  â”œâ”€â”€ Calculate base scores:
  â”‚   â”œâ”€â”€ Activity Score (0-100)
  â”‚   â”œâ”€â”€ Liquidity Score (0-100)
  â”‚   â”œâ”€â”€ Distribution Score (0-100)
  â”‚   â”œâ”€â”€ Momentum Score (-100 to +100)
  â”‚   â””â”€â”€ Risk Score (0-100)
  â”‚
  â””â”€â”€ Calculate Initial Trending Score:
      TrendingScore = (
        Activity * 0.3 +
        Liquidity * 0.2 +
        Distribution * 0.1 +
        (50 + Momentum/2) * 0.3 +
        (100 - Risk) * 0.1
      )
```

### **Step 1.3: Create Initial Ranking**
```
Sort all tokens by TrendingScore (descending)

Save to database:
  â”œâ”€â”€ token_scores table
  â”‚   â”œâ”€â”€ address
  â”‚   â”œâ”€â”€ trending_score
  â”‚   â”œâ”€â”€ on_chain_score
  â”‚   â”œâ”€â”€ social_score = NULL (initially)
  â”‚   â”œâ”€â”€ last_updated
  â”‚   â””â”€â”€ update_priority (high/medium/low)
  â”‚
  â””â”€â”€ Set update_priority:
      â”œâ”€â”€ Top 20 tokens â†’ high (update every 5 min)
      â”œâ”€â”€ Rank 21-100 â†’ medium (update every 30 min)
      â””â”€â”€ Rank 100+ â†’ low (update every 2 hours)
```

**Output**: Initial trending list ranked purely by on-chain metrics

---

## **Phase 2: Continuous On-Chain Monitoring** âš¡

**Goal**: Keep on-chain data fresh without overwhelming the system

### **Strategy: Tiered Update System**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              UPDATE FREQUENCY TIERS                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  Tier 1 (High Priority) - Top 20 tokens               â”‚
â”‚  â””â”€â”€ Update every: 5 minutes                          â”‚
â”‚  â””â”€â”€ Reason: Most volatile, user-watched             â”‚
â”‚                                                        â”‚
â”‚  Tier 2 (Medium Priority) - Rank 21-100               â”‚
â”‚  â””â”€â”€ Update every: 30 minutes                         â”‚
â”‚  â””â”€â”€ Reason: Moderate activity                        â”‚
â”‚                                                        â”‚
â”‚  Tier 3 (Low Priority) - Rank 100+                    â”‚
â”‚  â””â”€â”€ Update every: 2 hours                            â”‚
â”‚  â””â”€â”€ Reason: Low activity, background monitoring      â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Implementation Flow**
```
Every 1 minute (Background Job):

1. Check which tokens need updates:
   current_time = now()
   
   tokens_to_update = SELECT * FROM token_scores WHERE
     (priority = 'high' AND last_updated < current_time - 5 min) OR
     (priority = 'medium' AND last_updated < current_time - 30 min) OR
     (priority = 'low' AND last_updated < current_time - 2 hours)

2. Fetch new transaction data:
   FOR each token in tokens_to_update:
     â””â”€â”€ Query indexer for new transactions since last_updated
     â””â”€â”€ If new transactions exist:
         â”œâ”€â”€ Run incremental on-chain analysis
         â””â”€â”€ Update scores in database

3. Recalculate rankings:
   â””â”€â”€ Re-sort all tokens by trending_score
   â””â”€â”€ Update priority tiers based on new ranks

4. Cache the top 100:
   â””â”€â”€ Store in Redis/memory for fast API access
```

---

## **Phase 3: Smart Social Media Updates** ğŸ¦

**Goal**: Add social sentiment ONLY for tokens that are actually trending

### **Strategy: Selective Social Fetching**
```
Every 5 minutes (Separate Job):

1. Identify candidates for social analysis:
   
   candidates = Top 20 tokens by current trending_score
   
   WHY ONLY TOP 20?
   â”œâ”€â”€ Social APIs have rate limits (Twitter: 450 req/15min)
   â”œâ”€â”€ Social data only matters for trending tokens
   â”œâ”€â”€ Users only care about top performers
   â””â”€â”€ Cost optimization (AI analysis is expensive)

2. Fetch social media posts:
   
   FOR each token in candidates:
     â””â”€â”€ Search Twitter/Reddit for: "$SYMBOL" OR "TokenName"
     â””â”€â”€ Time range: Last 24 hours
     â””â”€â”€ Collect:
         â”œâ”€â”€ Posts mentioning the token
         â”œâ”€â”€ Engagement metrics
         â””â”€â”€ Sentiment indicators

3. Analyze with AI:
   
   posts_batch = Combine all posts for top 20 tokens
   
   social_analysis = SocialMediaAggregator.analyzeTrends(posts_batch)
   
   FOR each token in social_analysis:
     â””â”€â”€ Calculate social_score (0-100):
         social_score = (
           sentiment_score * 40 +
           trending_score * 30 +
           engagement_rate * 20 +
           mention_velocity * 10
         )

4. Update database:
   
   UPDATE token_scores SET
     social_score = calculated_score,
     social_last_updated = now()
   WHERE address IN (top_20_addresses)
```

### **Combining On-Chain + Social Scores**
```
FINAL_TRENDING_SCORE Calculation:

IF token has social_score:
  â””â”€â”€ FINAL_SCORE = (
        on_chain_score * 0.60 +    â† Still primary signal
        social_score * 0.40         â† Bonus for social buzz
      )

ELSE (no social data):
  â””â”€â”€ FINAL_SCORE = on_chain_score  â† Pure on-chain ranking

Re-rank ALL tokens by FINAL_SCORE





ğŸš€ OffChain API

The OffChain API is a backend service that connects to Redis Cloud, fetches and updates token analytics data, and exposes REST endpoints for social sentimentâ€“based token rankings.
It integrates social media analytics with on-chain scores and provides fast access to data for dashboards or web apps.

âš™ï¸ Tech Stack

Node.js + Express

TypeScript

Redis Cloud (for caching & storage)

CORS-enabled REST API

ğŸ§  Features

âœ… Fetch and rank tokens stored in Redis
âœ… Merge on-chain and social sentiment scores
âœ… Cache token rankings for performance
âœ… Auto-update tokens in rank batches
âœ… Expose clean API endpoints for frontend consumption

ğŸ”§ Environment Variables

Create a .env file in the same directory as your index.ts:

REDIS_HOST=redis-13615.c277.us-east-1-3.ec2.redns.redis-cloud.com
REDIS_PORT=13615
REDIS_USERNAME=default
REDIS_PASSWORD=pDQQrMEE5RQ9aMMqBw4WdKWItjNYmWHB
GOOGLE_API_KEY=your_google_api_key

ğŸ§© API Endpoints
Endpoint	Method	Description
/	GET	Health check for the API
/allposts	GET	Fetch all aggregated posts
/tokenpost	POST	Get posts for specific tokens
/social-analytics	POST	Run social analysis (Twitter + Reddit)
/update-social-scores	POST	Update token social scores in Redis
/token/:address	GET	Fetch a tokenâ€™s full data by address
/top-tokens?limit=50	GET	Get top-ranked tokens sorted by score
/clear-cache	POST	Clear the in-memory cache
ğŸ§® Scoring Logic

Each tokenâ€™s final score combines on-chain and social data:

finalScore = (0.6 Ã— onChainTrendingScore) + (0.4 Ã— socialScore)


Social Score is computed from:

Sentiment

Mentions & engagement

Risk level (low / medium / high)

Confidence of analysis

ğŸ•’ Automatic Updates

The API automatically updates token scores at different intervals:

Rank Range	Frequency
0â€“20	Every 5 minutes
20â€“100	Every 20 minutes
100+	Every 30 minutes

Manual trigger:

POST /update-social-scores

ğŸª„ Run Locally
npm install
npm run dev


API runs on:
ğŸ‘‰ http://localhost:3002

ğŸ“Š Example Request
curl -X POST http://localhost:3002/update-social-scores \
  -H "Content-Type: application/json" \
  -d '{"startRank":0,"endRank":20}'
